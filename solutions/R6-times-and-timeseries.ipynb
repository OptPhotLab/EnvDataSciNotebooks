{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Introduction\n",
                "\n",
                "In this session we will tackle the issue of dates and time-series.\n",
                "\n",
                "Time-series are everywhere in environmental data.  At its most basic\n",
                "time-series data consist of two columns (vectors) of data. The first is\n",
                "the date (time) column (plotted as X-axis on graph) and the second\n",
                "column is the variable of interest that changes as a function of time.\n",
                "\n",
                "There are two things we should keep in mind when working with\n",
                "time-series data. Firstly it is easiest to get dates into the correct\n",
                "datetime format as soon as possible, this way we can let the computer\n",
                "do the hard work when it comes to plotting etc. Secondly, we\n",
                "should keep in mind is that there are any number of data analysis and\n",
                "statistical methods specifically designed for time-series data. There\n",
                "are also caveats related to using standard statistical techniques\n",
                "(e.g. linear regression) to time-series data, so watch out for these!\n",
                "   \n",
                "In this session we will explain how R handles dates, and we will also\n",
                "look at auto-correlation and cross-correlation of time-series, which\n",
                "are two concepts that are of great importance in time-series analysis and\n",
                "find application in a number of different places (e.g. Durbin Watson\n",
                "statistic, ARIMA models, eddy co-variance calculations etc).\n",
                "\n",
                "#1. What is a date and datetime exactly?\n",
                "\n",
                "The simplest representation of dates in R, is the suitably named\n",
                "*date* object. You can create one of these by converting a character\n",
                "of correct form. Use the *as.Date()* function to convert\n",
                "*a.great.date.char* to *a.great.R.date*\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "a.great.char.date <- \"2017-10-28\"  \n",
                "typeof(a.great.char.date)\n",
                "print(a.great.char.date)\n",
                "\n",
                "a.great.R.date <- as.Date(a.great.char.date)\n",
                "print(a.great.R.date)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "You can also use the *Sys.Date()* function to print the current date\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Sys.Date()\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Date and character variables look similar, so why don't we just\n",
                "use the character representation \"2017-10-28\" rather than the special\n",
                "*date* object?  One example of the usefulness of dates is the fact\n",
                "that we can perform arithmetic with dates. Try it out; what is the\n",
                "difference between the date today *Sys.Date()* and *a.great.R.date*?\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "time.diff = Sys.Date() - a.great.R.date\n",
                "print(time.diff)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can use a similar function to print out the current time and date\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Sys.time()\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This is referred to as a datetime object, and is the main object type\n",
                "that we will deal with. Datetime objects contains date, time and also\n",
                "specifies the local timezone. Let's inspect a datetime object to find\n",
                "out what we are dealing with:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "just.before <- Sys.time()\n",
                "str(just.before)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In R, datetimes are either categorised as *POSIXct* or *POSIXlt*,\n",
                "which are the different methods R uses to store the information. \n",
                "\n",
                "Can you convert *just.before* from *POSIXct* to a *POSIXlt*?:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "just.before.lt <- as.POSIXlt(just.before)\n",
                "str(just.before.lt)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "So what's the difference then? \n",
                "\n",
                "POSIXlt stores dates as lists (remember those?). Whereas POSIXct\n",
                "stores dates as the number of seconds that have elapsed since a\n",
                "particular date (1 January 1970, which you can read\n",
                "all about here [the unix Epoch](https://en.wikipedia.org/wiki/Unix_time)).\n",
                "\n",
                "So when to use which? In all honesty I am not 100% sure. However as\n",
                "POSIXct takes less memory and is somewhat simpler then perhaps that\n",
                "is the preferred option. \n",
                "\n",
                "# 2. Dates and real data\n",
                "\n",
                "Let's see how we would read in some dates using real data. We have\n",
                "used this data before, but as a reminder GPP is an estimate of CO2\n",
                "exchange of tree canopies:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "gpp<-read.csv('../data/gppsmeardata_20160101120000.csv',header = T,sep = ',',dec='.')\n",
                "\n",
                "head(gpp)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Our task is to take the various columns of date and time information and\n",
                "convert these to a vector of type *datetime*. Let's go step by step,\n",
                "we will start with a new character vector of date:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "date.char<-paste(gpp$Year,gpp$Month,gpp$Day,sep = '-')\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "do the same for time, but this time set the *sep=:*:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "time.char<-paste(gpp$Hour,gpp$Minute,gpp$Second,sep = ':')\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "combine the two, and convert to POSIXc datetime:\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "gpp$datetime<-as.POSIXct(paste(date.char,time.char,sep = ' '))\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "we can also add the date as a separate column, which will be useful\n",
                "for plotting later on:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "gpp$date<-as.Date(date.char)\n",
                "head(gpp$date)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "To make our life easier in the following selection we will use daily\n",
                "data. We can use *aggregate* to calculate median values:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "gpp.daily <- aggregate(HYY_EDDY233.GPP ~ date, gpp, median)\n",
                "\n",
                "head(gpp.daily)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's use this data in the following sections...\n",
                "\n",
                "#3. Does data have a sense of history? \n",
                "\n",
                "A key aspect of analysing time-series data is understanding and\n",
                "dealing with history (or memory). History in the context of\n",
                "time-series refers to how current values (or future values) depend on\n",
                "past values. This is seen as trends in behaviour over time, and\n",
                "referred to as *non-stationary* in math jargon. Likewise *stationary*\n",
                "data has no trend, and both the mean and variability (variance)\n",
                "remains constant. Running a regression model with two non-stationary\n",
                "time-series can often lead to highly inflated R2 value, this is a\n",
                "common problem in economics and is known as [spurious\n",
                "regression](https://www.reed.edu/economics/parker/312/tschapters/S13_Ch_2.pdf).\n",
                "\n",
                "\n",
                "So how about our GPP data, is there a trend in time? As always, let's start\n",
                "with a graph...\n",
                "\n",
                "When we graph time-series data, we can use the *scales* package to make\n",
                "our life easier.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(ggplot2)\n",
                "library(scales) \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We then use the *scale_x_date* function from scales to format the\n",
                "x-axis in 1 day time steps :\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ggplot(gpp.daily,aes(x=date,y=HYY_EDDY233.GPP))+\n",
                "  geom_point()+ ylab(\"GPP [umol/m2/s]\") +\n",
                "  scale_x_date(breaks = date_breaks('1 day'),\n",
                "               labels = date_format(\"%m-%d\"))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "It is impossible to read the x-axis here, so let's increase the time-step\n",
                "to more days, you can also change the *date_format argument* to \n",
                "*%b-%d* as well if you like:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ggplot(gpp.daily,aes(x=date,y=HYY_EDDY233.GPP))+\n",
                "  geom_point() +  ylab(\"GPP [umol/m2/s]\") +\n",
                "  scale_x_date(breaks = date_breaks('30 day'),\n",
                "               labels = date_format(\"%b-%d\")) \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Once we identify history in our data then we can start to do\n",
                "interesting things; we might attempt to remove the dependence (by\n",
                "differencing), and we can also look at auto-correlation... \n",
                "\n",
                "## What is auto-correlation?\n",
                "\n",
                "In simple terms auto-correlation is the correlation between a variable and\n",
                "itself shifted in time. The shift in time is referred to as the\n",
                "*lag*. Typically we compute auto-correlation for a whole range of lags,\n",
                "and then plot the output as an **auto-correlation function**, which is\n",
                "a plot of lag Vs correlation value. Confused? well let's walk through\n",
                "a manual example using our GPP data.\n",
                "\n",
                "Lagging a variable simply shifts it in time. We can do that for\n",
                "our GPP data here and plot against the original time-series\n",
                "(which is shortened to the same length). Let's lag by 30 days and\n",
                "plot the output:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "lag <- 30\n",
                "n <- length(gpp.daily$HYY_EDDY233.GPP)\n",
                "gpp.lag <- gpp.daily$HYY_EDDY233.GPP[1:(n-lag)]\n",
                "gpp.short <- gpp.daily$HYY_EDDY233.GPP[(1+lag):n]  \n",
                "date.short <-  gpp.daily$date[(1+lag):n]  \n",
                "\n",
                "df.lag <- data.frame(date.short,gpp.lag,gpp.short)\n",
                "\n",
                "ggplot() + \n",
                "  geom_line(data = df.lag, aes(x = date.short, \n",
                "  y = gpp.short), color = \"red\") +\t\t \n",
                "  geom_line(data = df.lag, aes(x = date.short,\n",
                "   y = gpp.lag), color = \"blue\") + \n",
                "   ylab(\"GPP [umol/m2/s]\") +\n",
                "  scale_x_date(breaks = date_breaks('30 day'),\n",
                "               labels = date_format(\"%b-%d\")) \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Auto-correlation is the correlation between these two variables\n",
                "(the time-series and its lagged version). The following function *lags*\n",
                "data and works out the correlation:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "lag.corr <- function(ts, lag){\n",
                "  a <- ts-mean(ts) \t \n",
                "  n <- length(a)\n",
                "  b <- a[1:(n-lag)]\n",
                "  c <- a[(1+lag):n]  \n",
                "  # this line is similar to cor function\t\n",
                "  sum(b * c)/sum(a^2)\n",
                "}\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "note that we do not use the built-in *cor* function on our lagged data\n",
                "to work out correlation, because the strict definition means that we\n",
                "use this alternative method instead. Click\n",
                "[here](https://stackoverflow.com/questions/32569322/apparent-error-in-r-acf-calculation/32570260#32570260)\n",
                "to find out about the differences and see where the function came\n",
                "from.\n",
                "\n",
                "What's the GPP auto-correlation at 30 days?\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "lag.corr(gpp.daily$HYY_EDDY233.GPP,30)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "How about lag=0? \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "lag.corr(gpp.daily$HYY_EDDY233.GPP,0)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "that is equivalent to calculating the correlation of a time-series with\n",
                "itself!\n",
                "\n",
                "There is no need to do compute all lag values manually, we can use the\n",
                "function *acf( )* to automatically graph the \n",
                "autocorrelation function, just set the *lag.max* parameter to \n",
                "sensible value (maximum number of days),try it out on the midday *gpp* data:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "z<-acf(gpp.daily$HYY_EDDY233.GPP,lag.max=100)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "You can see that for a whole bunch of lag values then we have significant\n",
                "correlation, this means (as is somewhat obvious) that our data shows\n",
                "auto-correlation i.e. trends over time.\n",
                "\n",
                "Let's double check our manual calculation:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "lag.corr(gpp.daily$HYY_EDDY233.GPP,25)\n",
                "z[25]\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "So when might we use this result? Well zero auto-correlation \n",
                "of residuals is an assumption of linear regression models. In \n",
                "fact the [Durbin Watson](https://en.wikipedia.org/wiki/Durbin%E2%80%93Watson_statistic) statistic specifically tests for this. \n",
                "\n",
                "# 4. How to forget: *differencing* a time-series\n",
                "\n",
                "Differencing a time-series can be used to reduce auto-correlation.  It is\n",
                "a simple idea, we just take the difference between adjacent values. We\n",
                "use the *diff* function in R to do this. \n",
                "\n",
                "Try it out below:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "gpp.diff <- diff(gpp.daily$HYY_EDDY233.GPP)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Note that the length of gpp.diff is one less than the the length\n",
                "of the original GPP time-series. Let's add a NA so we can fit\n",
                "it into the original dataframe, and plot the output:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "gpp.daily$gpp.diff <- c(gpp.diff, NA)\n",
                "\n",
                "ggplot(gpp.daily,aes(x=date,y=gpp.diff))+\n",
                "  geom_point() +  ylab(\"GPP difference\") +\n",
                "  scale_x_date(breaks = date_breaks('30 day'),\n",
                "               labels = date_format(\"%b-%d\")) \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "let's see what the acf plot looks like (note that we have to use the\n",
                "gpp.diff variable here not the dataframe, as acf fails for vectors\n",
                "with NA):\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "acf(gpp.diff,lag.max=100)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Notice how different this *acf* plot is to the\n",
                "undifferenced data? The rapid fall-off in the acf means that our data\n",
                "no longer remembers so much of its history.\n",
                "\n",
                "So is the difference time-series stationary? well the mean stays constant, \n",
                "but the variabilty (variance) is still a funcion of time. So we cannot\n",
                "say that our time-series is stationary in variance. Transforming data\n",
                "(using e.g. square root) is typically used for dealing with changing\n",
                "variance, see [here](https://robjhyndman.com/uwafiles/6-Stationarity-Transformations-Differencing.pdf).\n",
                "\n",
                "If you're working on time-series data, try differencing it and removing the\n",
                "trend to avoid the curse of spurious correlations.\n",
                "\n",
                "# 5. Putting our new knowledge to work: cross correlation.\n",
                "\n",
                "What we have done so far is a little theoretical, how can\n",
                "we use this information to learn something about our data? For \n",
                "that we need a theory...\n",
                "\n",
                "In the boreal regions we think that (air) temperature is really a key\n",
                "variable that precedes GPP seasonality. Therefore it is reasonable\n",
                "to assume that GPP lags temperature by some number of days. \n",
                "Can we show this? Can we even work out an estimate of the lag? \n",
                "\n",
                "Let's load some temperature data:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "T168<-read.csv('../data/T168_20160101120000.csv',header = T,sep = ',',dec='.')\n",
                "\n",
                "head(T168)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "There are some missing values in our temperature data, let's fill \n",
                "them in using interpolation before we move onto our next bit of\n",
                "analysis:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(zoo)\n",
                "T168$HYY_META.T168i <- na.approx(T168$HYY_META.T168)\n",
                "\n",
                "sum(is.na(T168$HYY_META.T168))\n",
                "sum(is.na(T168$HYY_META.T168i))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Extract daily values, like our GPP above. You try out maximum for this \n",
                "(rather than median):\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "T168$date <-gpp$date\n",
                "T168.daily <- aggregate(HYY_META.T168i ~ date, T168, max)\n",
                "\n",
                "head(T168.daily)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "When we plot GPP and temperature together, what do we see?\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "gpp.daily$HYY_META.T168 <- T168.daily$HYY_META.T168\n",
                "\n",
                "ggplot() + \n",
                "  geom_line(data = gpp.daily, aes(x = date, \n",
                "  y = HYY_EDDY233.GPP), color = \"red\") +\t\t \n",
                "  geom_line(data = gpp.daily, aes(x = date,\n",
                "   y = HYY_META.T168), color = \"blue\") + \n",
                "   \n",
                "  scale_x_date(breaks = date_breaks('30 day'),\n",
                "               labels = date_format(\"%b-%d\")) \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now here comes the new bit, where we apply *cross-correlation*. \n",
                "Cross-correlation is just like auto-correlation, only we calculate\n",
                "lags between two *different* variables, at differing lags. This\n",
                "allows us to estimate the lag at which maximum correlation occurs. \n",
                "\n",
                "Finally, time to try out the ccf and find out if GPP lags temperature:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ccf(gpp.daily$HYY_EDDY233.GPP,gpp.daily$HYY_META.T168,lag.max=40)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now this is a confusing picture. From these results is appears\n",
                "that temperature actually follows photosynthesis! How about if\n",
                "select just the spring recovery period?\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "gpp.spring.daily <-gpp.daily[25:180,]\n",
                "\n",
                "\n",
                "ggplot() + \n",
                "  geom_line(data = gpp.spring.daily, aes(x = date, \n",
                "  y = HYY_EDDY233.GPP), color = \"red\") +\t\t \n",
                "  geom_line(data = gpp.spring.daily, aes(x = date,\n",
                "   y = HYY_META.T168), color = \"blue\") + \n",
                "   \n",
                "  scale_x_date(breaks = date_breaks('30 day'),\n",
                "               labels = date_format(\"%b-%d\")) \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now try the ccf on the spring recovery data:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ccf(gpp.spring.daily$HYY_EDDY233.GPP,gpp.spring.daily$HYY_META.T168,lag.max=40)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now that is more like it! The positive values imply that GPP lags\n",
                "temperature during the spring, and there is also a secondary peak\n",
                "visible.\n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "R",
            "langauge": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.4.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
